# ğŸš€ Dá»± Ã¡n Antigravity (PySpark Edition)
## PhÃ¢n tÃ­ch LiÃªn thá»‹ trÆ°á»ng & Dá»± bÃ¡o GiÃ¡ VÃ ng

> **PhiÃªn báº£n PySpark** â€” Sá»­ dá»¥ng Apache Spark cho xá»­ lÃ½ dá»¯ liá»‡u.

---

## âš¡ CÃ´ng nghá»‡ PySpark Ä‘Æ°á»£c sá»­ dá»¥ng

| Module | PySpark Usage |
|--------|---------------|
| **Data Collection** | `SparkSession`, `createDataFrame`, Window functions (forward/backward fill), `describe()` |
| **Correlation** | `spark_df.stat.corr()` cho Pearson correlation |
| **XGBoost Features** | Window functions cho lags, rolling MA/STD/MIN/MAX, `F.lag()`, `F.dayofweek()` |
| **Data Storage** | Spark Schema export, DataFrame API |

---

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
antigravity_spark/
â”œâ”€â”€ main.py                  # Pipeline chÃ­nh (PySpark + 2 giai Ä‘oáº¡n)
â”œâ”€â”€ spark_session.py         # SparkSession management + HADOOP_HOME
â”œâ”€â”€ data_collection.py       # Thu tháº­p & xá»­ lÃ½ dá»¯ liá»‡u (PySpark)
â”œâ”€â”€ correlation_analysis.py  # TÆ°Æ¡ng quan (PySpark stat.corr)
â”œâ”€â”€ model_xgboost.py         # XGBoost (PySpark feature engineering)
â”œâ”€â”€ model_prophet.py         # Prophet + Regressors
â”œâ”€â”€ evaluation.py            # ÄÃ¡nh giÃ¡ & so sÃ¡nh
â”œâ”€â”€ visualizations.py        # Biá»ƒu Ä‘á»“
â”œâ”€â”€ period_comparison.py     # So sÃ¡nh liÃªn giai Ä‘oáº¡n
â”œâ”€â”€ requirements.txt         # + pyspark>=3.5.0
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ merged_data.csv
â”‚   â”œâ”€â”€ prophet_data.csv
â”‚   â””â”€â”€ spark_schema.txt     # Spark DataFrame schema
â””â”€â”€ output/
    â”œâ”€â”€ report.txt
    â””â”€â”€ figures/              # ~24 biá»ƒu Ä‘á»“
```

---

## âš™ï¸ CÃ i Ä‘áº·t & Cháº¡y

### YÃªu cáº§u

- **Python 3.10+**
- **Java 17** (required by PySpark)
- **Hadoop winutils** (Windows only)

### CÃ i Ä‘áº·t

```bash
# 1. CÃ i Java (Windows)
winget install Microsoft.OpenJDK.17

# 2. CÃ i thÆ° viá»‡n Python
pip install -r requirements.txt

# 3. Cháº¡y pipeline
# Windows PowerShell:
$env:JAVA_HOME='C:\Program Files\Microsoft\jdk-17.0.18.8-hotspot'
$env:PATH="$env:JAVA_HOME\bin;$env:PATH"
$env:PYTHONIOENCODING='utf-8'
python main.py
```

---

## ğŸ“Š Káº¿t quáº£ so sÃ¡nh 2 giai Ä‘oáº¡n

### TÆ°Æ¡ng quan Pearson (PySpark `stat.corr`)

| Cáº·p | 2014-2019 | 2020-2025 | Thay Ä‘á»•i |
|-----|-----------|-----------|----------|
| Gold â†” WTI | +0.198 | âˆ’0.073 | â†“ |
| Gold â†” DXY | âˆ’0.112 | +0.101 | â†‘ Ä‘áº£o chiá»u |
| **WTI â†” DXY** | **âˆ’0.852** | **+0.465** | **â†‘ Ä‘áº£o chiá»u hoÃ n toÃ n** |

### Hiá»‡u suáº¥t mÃ´ hÃ¬nh

| MÃ´ hÃ¬nh | Giai Ä‘oáº¡n | MAE | RMSE | MAPE |
|---------|-----------|-----|------|------|
| XGBoost | 2014-2019 | 53.02 | 81.70 | 3.58% |
| Prophet | 2014-2019 | 150.23 | 168.09 | 12.10% |
| XGBoost | 2020-2025 | 629.45 | 810.03 | 17.07% |
| Prophet | 2020-2025 | 698.10 | 809.02 | 37.94% |

### PySpark Feature Engineering (Window Functions)

Features Ä‘Æ°á»£c táº¡o hoÃ n toÃ n báº±ng PySpark:
- **Lag features:** `F.lag("Gold", n).over(Window.orderBy("date"))`
- **Rolling stats:** `F.avg/stddev/min/max("Gold").over(Window.rowsBetween(-(w-1), 0))`
- **Returns:** Computed via `F.col()` / `F.lag()`
- **Date features:** `F.dayofweek()`, `F.month()`, `F.quarter()`

---

## ğŸ› ï¸ Tech Stack

| ThÆ° viá»‡n | Má»¥c Ä‘Ã­ch |
|----------|----------|
| `pyspark` | **Data processing, feature engineering, correlation** |
| `yfinance` | Thu tháº­p dá»¯ liá»‡u |
| `pandas`, `numpy` | Model training interface |
| `xgboost` + `optuna` | ML model + optimization |
| `prophet` | Chuá»—i thá»i gian |
| `matplotlib`, `seaborn` | Visualizations |
| `statsmodels` | Granger Causality |

---

## ğŸ“„ Quy trÃ¬nh (PySpark Edition)

```mermaid
graph TD
    S[SparkSession] --> A
    A[Yahoo Finance<br>pandas] --> B[PySpark DataFrame<br>createDataFrame]
    B --> C[Preprocessing<br>Window ffill/bfill]
    C --> D1[Pearson Corr<br>stat.corr]
    C --> D2[Feature Eng<br>Window Functions]
    D2 --> E1[toPandas]
    E1 --> F1[XGBoost + Optuna]
    C --> E2[toPandas]
    E2 --> F2[Prophet]
    F1 --> G[Evaluation]
    F2 --> G
    G --> H[Report + Charts]
```

---

*Dá»± Ã¡n Antigravity (PySpark Edition) â€” Phá»¥c vá»¥ má»¥c Ä‘Ã­ch há»c thuáº­t vÃ  nghiÃªn cá»©u.*
